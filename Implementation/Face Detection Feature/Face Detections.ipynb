{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Face Detection with Deep Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Locating a face in a photograph : finding the coordinate of the face in the image.\n",
    "Localization - demarcating the extent of the face, often via a bounding box around the face."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Method 01 : Cascade Classifiers + AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot photo with detected faces using opencv cascade classifier\n",
    "import cv2\n",
    "import os\n",
    "import uuid\n",
    "import time\n",
    "\n",
    "def detect_face(file_name):\n",
    "\t# load the photograph\n",
    "\tpixels = cv2.imread(file_name)\n",
    "\t# load the pre-trained model\n",
    "\tclassifier = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "\t# perform face detection\n",
    "\tbboxes = classifier.detectMultiScale(pixels,1.05,3)\n",
    "\n",
    "\t# print bounding box for each detected face\n",
    "\tfor box in bboxes:\n",
    "\t\t# extract\n",
    "\t\tx, y, width, height = box\n",
    "\t\tx2, y2 = x + width, y + height\n",
    "\t\t# draw a rectangle over the pixels\n",
    "\t\tcv2.rectangle(pixels, (x, y), (x2, y2), (0,0,255), 1)\n",
    "\t# show the image\n",
    "\t# cv2.imshow('face detection', pixels)\n",
    "\t#Detect the number of faces detected\n",
    "\tprint(\"Number of Faces Detected in {} : \".format(file_name),len(bboxes))\n",
    "\n",
    "capture = cv2.VideoCapture(0)\n",
    "img_num=1\n",
    "while img_num<=25:\n",
    "\tprint('Collecting image {}'.format(img_num))\n",
    "\tret,frame =capture.read()\n",
    "\timg_name = os.path.join('./data/images_haar/',f'{str(img_num)}.jpg')\n",
    "\tif ret == 0:\n",
    "\t\tprint(\"Frame Not Captured\")\n",
    "\telse:\n",
    "\t\tcv2.imwrite(img_name, frame)\n",
    "\t\timg_num+=1\n",
    "\t\t# cv2.imshow('Frame: '+str(img_num), frame)\n",
    "\t\ttime.sleep(0.5)\n",
    "\t# keep the window open until we press a key\n",
    "\tdetect_face(img_name)\n",
    "\t\n",
    "\tif cv2.waitKey(1) & 0xFF==ord('q'): break\n",
    "\n",
    "capture.release()\n",
    "# close the window \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above method,  \n",
    "- Certain boxes would be recognized as faces, although they are not.\n",
    "- No detection of inverted faces, tilted faces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Method 02 : Using Multi-Task Cascaded Convolutional Neural Network (MTCNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract and plot each detected face in a photograph\n",
    "from matplotlib import pyplot\n",
    "from matplotlib.patches import Rectangle\n",
    "from matplotlib.patches import Circle\n",
    "from mtcnn.mtcnn import MTCNN\n",
    "\n",
    "# draw each face separately\n",
    "def draw_faces(filename, result_list):\n",
    "\t# load the image\n",
    "\tdata = pyplot.imread(filename)\n",
    "\t# plot each face as a subplot\n",
    "\tfor i in range(len(result_list)):\n",
    "\t\t# get coordinates\n",
    "\t\tx1, y1, width, height = result_list[i]['box']\n",
    "\t\tx2, y2 = x1 + width, y1 + height\n",
    "\t\t# define subplot\n",
    "\t\tpyplot.subplot(1, len(result_list), i+1)\n",
    "\t\tpyplot.axis('off')\n",
    "\t\t# plot face\n",
    "\t\tpyplot.imshow(data[y1:y2, x1:x2])\n",
    "\t# show the plot\n",
    "\tpyplot.show()\n",
    "def detect_face_using_mtcnn(filename):\n",
    "\t#---------------------Check For Exception Handling \n",
    "\t# load image from file\n",
    "\tpixels = pyplot.imread(filename)\n",
    "\t# create the detector, using default weights\n",
    "\tdetector = MTCNN()\n",
    "\t# detect faces in the image\n",
    "\tfaces = detector.detect_faces(pixels)\n",
    "\t# display faces on the original image\n",
    "\tprint(\"Number of faces: \",len(faces))\n",
    "\t# draw_faces(filename, faces)\n",
    "\n",
    "import cv2\n",
    "import os\n",
    "import uuid\n",
    "import time\n",
    "\n",
    "capture = cv2.VideoCapture(0)\n",
    "img_num=1\n",
    "while img_num<=10:\n",
    "\tinit = time.time()\n",
    "\tprint('Collecting image {}'.format(img_num))\n",
    "\tcaptured,frame =capture.read()\n",
    "\timg_name = os.path.join('./data/images_mtcnn/',f'{str(img_num)}.jpg')\n",
    "\tif not captured:\n",
    "\t\tprint(\"Frame Not Captured\")\n",
    "\telse:\n",
    "\t\tcv2.imwrite(img_name, frame)\n",
    "\t\timg_num+=1\n",
    "\t\t# cv2.imshow('Frame: '+str(img_num), frame)\n",
    "\t\ttime.sleep(0.5)\n",
    "\t# keep the window open until we press a key\n",
    "\t\tdetect_face_using_mtcnn(img_name)\n",
    "\t\n",
    "\tif cv2.waitKey(1) & 0xFF==ord('q'): break\n",
    "\tfps = 1/(time.time() - init)\n",
    "\tprint('Fps: {}'.format(fps))\n",
    "\n",
    "capture.release()\n",
    "# close the window \n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above MTCNN technique,\n",
    "- Detection of inverted faces and tilted faces (A few tilted images could be omitted)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "01e904f80db565dd0b59e435e4c9f07ce7d572248c4b701c0b4361e62be5e430"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
