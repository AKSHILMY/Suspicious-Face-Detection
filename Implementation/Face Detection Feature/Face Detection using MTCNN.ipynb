{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Face Detection with Deep Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Locating a face in a photograph : finding the coordinate of the face in the image.\n",
    "Localization - demarcating the extent of the face, often via a bounding box around the face."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Using Multi-Task Cascaded Convolutional Neural Network (MTCNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract and plot each detected face in a photograph\n",
    "from matplotlib import pyplot\n",
    "from matplotlib.patches import Rectangle\n",
    "from matplotlib.patches import Circle\n",
    "from mtcnn.mtcnn import MTCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# draw each face separately\n",
    "def draw_faces(filename, result_list):\n",
    "\t# load the image\n",
    "\tdata = pyplot.imread(filename)\n",
    "\t# plot each face as a subplot\n",
    "\tfor i in range(len(result_list)):\n",
    "\t\t# get coordinates\n",
    "\t\tx1, y1, width, height = result_list[i]['box']\n",
    "\t\tx2, y2 = x1 + width, y1 + height\n",
    "\t\t# define subplot\n",
    "\t\tpyplot.subplot(1, len(result_list), i+1)\n",
    "\t\tpyplot.axis('off')\n",
    "\t\t# plot face\n",
    "\t\tpyplot.imshow(data[y1:y2, x1:x2])\n",
    "\t# show the plot\n",
    "\tpyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_face_using_mtcnn(img_name):\n",
    "\tpixels = cv2.imread(img_name)\n",
    "\tdetector = MTCNN()\n",
    "\tfaces = detector.detect_faces(pixels)\n",
    "\tprint(\"Number of faces: \",len(faces))\n",
    "\t# draw_faces(filename, faces)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import cv2\n",
    "import os\n",
    "import uuid\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "capture = cv2.VideoCapture(0)\n",
    "img_num=1\n",
    "while img_num<=10:\n",
    "\tinit = time.time()\n",
    "\tprint('Collecting image {}'.format(img_num))\n",
    "\tcaptured,frame =capture.read()\n",
    "\timg_name = os.path.join('./data/images_mtcnn/',f'{str(img_num)}.jpg')\n",
    "\tif not captured:\n",
    "\t\tprint(\"Frame Not Captured\")\n",
    "\telse:\n",
    "\t\tcv2.imwrite(img_name, frame)\n",
    "\t\timg_num+=1\n",
    "\t\t\n",
    "\t\ttime.sleep(0.5)\n",
    "\t\n",
    "\t\tdetect_face_using_mtcnn(img_name)\n",
    "\t\n",
    "\tif cv2.waitKey(1) & 0xFF==ord('q'): break\n",
    "\tfps = 1/(time.time() - init)\n",
    "\tprint('Fps: {}'.format(fps))\n",
    "\n",
    "capture.release()\n",
    "# close the window \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above MTCNN technique,\n",
    "- Detection of inverted faces and tilted faces (A few tilted images could be omitted)\n",
    "- The Images are written - storage issue\n",
    "- The detection time needs to be optimized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.1 Using 'asyncio' python library to fasten the code using asynchronous programming :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract and plot each detected face in a photograph\n",
    "\n",
    "from matplotlib import pyplot\n",
    "from matplotlib.patches import Rectangle\n",
    "from matplotlib.patches import Circle\n",
    "from mtcnn.mtcnn import MTCNN\n",
    "from zmq import NULL\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# draw each face separately\n",
    "def draw_faces(filename, result_list):\n",
    "\t# load the image\n",
    "\tdata = pyplot.imread(filename)\n",
    "\t# plot each face as a subplot\n",
    "\tfor i in range(len(result_list)):\n",
    "\t\t# get coordinates\n",
    "\t\tx1, y1, width, height = result_list[i]['box']\n",
    "\t\tx2, y2 = x1 + width, y1 + height\n",
    "\t\t# define subplot\n",
    "\t\tpyplot.subplot(1, len(result_list), i+1)\n",
    "\t\tpyplot.axis('off')\n",
    "\t\t# plot face\n",
    "\t\tpyplot.imshow(data[y1:y2, x1:x2])\n",
    "\t# show the plot\n",
    "\tpyplot.show()\n",
    "\t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_face_using_mtcnn(filename):\n",
    "\t#---------------------Check For Exception Handling \n",
    "\t# load image from file\n",
    "\tpixels = pyplot.imread(filename)\n",
    "\t# create the detector, using default weights\n",
    "\tdetector = MTCNN()\n",
    "\t# detect faces in the image\n",
    "\tfaces = detector.detect_faces(pixels)\n",
    "\t# display faces on the original image\n",
    "\tprint(\"Number of faces: \",len(faces))\n",
    "\t# draw_faces(filename, faces)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import cv2\n",
    "import os\n",
    "import uuid\n",
    "import time\n",
    "import asyncio\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "async def captureVideo():\n",
    "\tglobal img_num,img_name,frame\n",
    "\ttask = asyncio.create_task(write())\n",
    "\tprint('Collecting image {}'.format(img_num))\n",
    "\tcaptured,frame =capture.read()\n",
    "\timg_name = os.path.join('./data/images_mtcnn/',f'{str(img_num)}.jpg')\n",
    "\tif not captured:\n",
    "\t\tprint(\"Frame Not Captured\")\n",
    "\telse:\n",
    "\t\timg_num+=1\n",
    "\t\t# cv2.imshow('Frame: '+str(img_num), frame)\n",
    "\t\tawait asyncio.sleep(0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "async def write():\n",
    "\tcv2.imwrite(img_name, frame)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\t\n",
    "capture = cv2.VideoCapture(0)\n",
    "img_num=1\n",
    "img_name = \"\"\n",
    "frame = NULL\n",
    "while img_num<=10:\n",
    "\tinit = time.time()\n",
    "\ttry: \n",
    "\t\tloop = asyncio.get_running_loop()\n",
    "\texcept RuntimeError:\n",
    "\t\tloop=None\n",
    "\tif loop and loop.is_running():\n",
    "\t\tprint(\"----------------------------------------------------------------\")\n",
    "\t\tawait captureVideo()\n",
    "\telse:\n",
    "\t\tasyncio.run(captureVideo())\n",
    "\t# keep the window open until we press a key\n",
    "\tdetect_face_using_mtcnn(img_name)\n",
    "\t\n",
    "\tif cv2.waitKey(1) & 0xFF==ord('q'): break\n",
    "\tfps = 1/(time.time() - init)\n",
    "\tprint('Fps: {}'.format(fps))\n",
    "\n",
    "capture.release()\n",
    "# close the window \n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.2 Using Multi-threading :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from threading import Thread\n",
    "import cv2, time\n",
    "from matplotlib import pyplot\n",
    "from matplotlib.patches import Rectangle\n",
    "from matplotlib.patches import Circle\n",
    "from mtcnn.mtcnn import MTCNN\n",
    "import sys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class VideoStreamWidget(object):\n",
    "    def __init__(self, src=0):\n",
    "        self.capture = cv2.VideoCapture(src)\n",
    "        # Start the thread to read frames from the video stream\n",
    "        self.thread = Thread(target=self.update, args=())\n",
    "        self.thread.daemon = True\n",
    "        self.thread.start()\n",
    "\n",
    "    def update(self):\n",
    "        # Read the next frame from the stream in a different thread\n",
    "        while True:\n",
    "            if self.capture.isOpened():\n",
    "                (self.status, self.frame) = self.capture.read()\n",
    "                time.sleep(.5)\n",
    "            else:\n",
    "                print(\"No Cam Found!\")\n",
    "                \n",
    "\n",
    "                \n",
    "\n",
    "    def write_frame(self,img_name):\n",
    "        # Display frames in main program\n",
    "        cv2.imwrite(img_name, self.frame)\n",
    "        key = cv2.waitKey(1)\n",
    "        if key == ord('q'):\n",
    "            self.capture.release()\n",
    "            cv2.destroyAllWindows()\n",
    "            exit(1)\n",
    "    # draw each face separately\n",
    "    def draw_faces(self,filename, result_list):\n",
    "        # load the image\n",
    "        data = pyplot.imread(filename)\n",
    "        # plot each face as a subplot\n",
    "        for i in range(len(result_list)):\n",
    "            # get coordinates\n",
    "            x1, y1, width, height = result_list[i]['box']\n",
    "            x2, y2 = x1 + width, y1 + height\n",
    "            # define subplot\n",
    "            pyplot.subplot(1, len(result_list), i+1)\n",
    "            pyplot.axis('off')\n",
    "            # plot face\n",
    "            pyplot.imshow(data[y1:y2, x1:x2])\n",
    "        # show the plot\n",
    "        pyplot.show()\n",
    "\n",
    "    def detect_face_using_mtcnn(self,filename):\n",
    "        print(f\"Detecting from : {img_name}\")\n",
    "        #---------------------Check For Exception Handling \n",
    "        # load image from file\n",
    "        pixels = pyplot.imread(filename)\n",
    "        # create the detector, using default weights\n",
    "        detector = MTCNN()\n",
    "        # detect faces in the image\n",
    "        faces = detector.detect_faces(pixels)\n",
    "        # display faces on the original image\n",
    "        num_faces = len(faces)\n",
    "        print(\"Number of faces: \",num_faces)\n",
    "        # draw_faces(filename, faces)\n",
    "        return faces\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "img_num=1\n",
    "if __name__ == '__main__':\n",
    "    video_stream_widget = VideoStreamWidget()\n",
    "    while True:\n",
    "        try:    \n",
    "            img_name = os.path.join('./data/images_mtcnn_multithreading/',f'{str(img_num)}.jpg')\n",
    "            video_stream_widget.write_frame(img_name)\n",
    "            faces = video_stream_widget.detect_face_using_mtcnn(img_name)\n",
    "            if len(faces)>1 :\n",
    "                video_stream_widget.draw_faces(img_name,faces)\n",
    "            if len(faces)<1 :\n",
    "                print(\"No Face Detected\")\n",
    "            img_num+=1\n",
    "        except AttributeError:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.2.1 Addressing the related storage issue using frame processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from threading import Thread\n",
    "import cv2, time\n",
    "from matplotlib import pyplot\n",
    "from matplotlib.patches import Rectangle\n",
    "from matplotlib.patches import Circle\n",
    "from mtcnn.mtcnn import MTCNN\n",
    "import sys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class VideoStreamWidget(object):\n",
    "    def __init__(self, src=0):\n",
    "        self.capture = cv2.VideoCapture(src)\n",
    "        # Start the thread to read frames from the video stream\n",
    "        self.thread = Thread(target=self.update, args=())\n",
    "        # self.thread.daemon = True\n",
    "        self.thread.start()\n",
    "\n",
    "    def update(self):\n",
    "        # Read the next frame from the stream in a different thread\n",
    "        while True:\n",
    "            if self.capture.isOpened():\n",
    "                (self.status, self.frame) = self.capture.read()\n",
    "                self.frame  = cv2.cvtColor(self.frame,cv2.COLOR_BGR2RGB)\n",
    "                time.sleep(.5)\n",
    "            else:\n",
    "                print(\"No Cam Found!\")\n",
    "                \n",
    "\n",
    "                \n",
    "\n",
    "    def write_frame(self,img_name):\n",
    "        # Display frames in main program\n",
    "        cv2.imwrite(img_name, self.frame)\n",
    "        key = cv2.waitKey(1)\n",
    "        if key == ord('q'):\n",
    "            self.capture.release()\n",
    "            cv2.destroyAllWindows()\n",
    "            exit(1)\n",
    "    # draw each face separately\n",
    "    def draw_faces(self,result_list):\n",
    "        # plot each face as a subplot\n",
    "        for i in range(len(result_list)):\n",
    "            # get coordinates\n",
    "            x1, y1, width, height = result_list[i]['box']\n",
    "            x2, y2 = x1 + width, y1 + height\n",
    "            # define subplot\n",
    "            pyplot.subplot(1, len(result_list), i+1)\n",
    "            pyplot.axis('off')\n",
    "            # plot face\n",
    "            pyplot.imshow(self.frame[y1:y2, x1:x2])\n",
    "        # show the plot\n",
    "        pyplot.show()\n",
    "\n",
    "    def detect_face_using_mtcnn(self):\n",
    "        print(f\"Detecting from Frame {img_num}:\")\n",
    "        #---------------------Check For Exception Handling \n",
    "        detector = MTCNN()\n",
    "        # detect faces in the image\n",
    "        faces = detector.detect_faces(self.frame)\n",
    "        # display faces on the original image\n",
    "        num_faces = len(faces)\n",
    "        print(\"Number of faces: \",num_faces)\n",
    "        # draw_faces(filename, faces)\n",
    "        return faces\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "img_num=1\n",
    "if __name__ == '__main__':\n",
    "    video_stream_widget = VideoStreamWidget()\n",
    "    while True:\n",
    "        try:    \n",
    "            # img_name = os.path.join('./data/images_mtcnn_multithreading/',f'{str(img_num)}.jpg')\n",
    "            # video_stream_widget.write_frame(img_name)\n",
    "            faces = video_stream_widget.detect_face_using_mtcnn()\n",
    "            if len(faces)>1 :\n",
    "                video_stream_widget.draw_faces(faces)\n",
    "            if len(faces)<1 :\n",
    "                print(\"No Face Detected\")\n",
    "            img_num+=1\n",
    "        except AttributeError:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above storage issue minimizal attempt using frame processing led to less efficiency of the detection algorithm "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.2.2 Addressing the related storage issue using python's 'tempfile' module\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "01e904f80db565dd0b59e435e4c9f07ce7d572248c4b701c0b4361e62be5e430"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
